# -ApacheSparkforDataScience
Source of this post https://www.linkedin.com/feed/update/urn:li:activity:6361735446703202304

How to get started with Apache Spark for Data Science? 

If you follow me you know I'm a Spark lover. For me it was an inspiration to go into the field of distributed machine learning and data science. I have some commits accepted in the code so I'm very happy about that too :)

Spark has become an standard when doing data science with large amount of data, if you have never heard of it, you can think of it as a Sklearn for big data but closer to Hadoop.

It's not easy to get started with Spark, and my recommendation is to use the Python API, is amazing and easy to interact. You don't lose performance when using the DataFrames API btw

So here is a short list of recommendations, articles, tutorials and more for PySpark and Spark in general:

-1. Learn programming in Python before going into PySpark.

0. Practice a lot. Use my kaggle-learning repo to compare Spark and Sklearn https://lnkd.in/eR4TghZ

1.  GitHub tutorials:

https://lnkd.in/eggV3Fk
https://lnkd.in/ehuwaR6

2. Use Optimus for data cleansing, preprocessing and feature engineering (also check OptimusML API):

- https://hioptimus.com
- https://lnkd.in/eHvX6c6

3. Articles to read (in order):
- https://lnkd.in/e2gKTHb
- https://lnkd.in/evTsuWg
- https://lnkd.in/eXmkFJZ
- https://lnkd.in/e3v_azS

4. Have fun :)
